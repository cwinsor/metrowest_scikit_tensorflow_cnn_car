{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1 at creating a CNN for the self-driving-car project\n",
    "# It used \"Keras\"\n",
    "# Unable to get TensorBoard working\n",
    "# Unable to get .fit() to work.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrowest machine learning - auto-driving car\n",
    "# This notebook trains the the CNN.\n",
    "# reference: https://keras.io/getting-started/sequential-model-guide/\n",
    "# specifically - I am looking at the cfar-10 in the \"examples\" which can be pulled from their github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some magic to the notebook will reload external python modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#?autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from pictures_test\n",
      "<class 'dict'>\n",
      "dict_keys(['DESCR', 'target_names', 'target', 'images'])\n",
      "There are 11 images\n",
      "There are 11 targets\n",
      "The image array is a (11, 480, 640, 3) of <class 'numpy.ndarray'>\n",
      "The class array is a (11,) of <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from data_loader import get_data\n",
    "\n",
    "foo = get_data('/home/chris/Documents/projects_scikit_tensorflow/metrowest_scikit_tensorflow_cnn_car/data_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DESCR', 'target_names', 'target', 'images'])\n",
      "11\n",
      "11\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "(11, 480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(foo.keys())\n",
    "print(len(foo['images']))\n",
    "print(len(foo['target']))\n",
    "print(type(foo['images'][0,0,0,0]))\n",
    "print(type(foo['target'][0]))\n",
    "print(foo['images'].shape)\n",
    "print(foo['images'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "x_train shape: (11, 480, 640, 3)\n",
      "11 train samples\n",
      "11 test samples\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "#num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_metrowest_auto_driving_car'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = foo['images']\n",
    "y_train = foo['target']\n",
    "x_test = foo['images']\n",
    "y_test = foo['target']\n",
    "\n",
    "print(type(x_train))\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train[0])\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "#if not data_augmentation:\n",
    "#    print('Not using data augmentation.')\n",
    "#    model.fit(x_train, y_train,\n",
    "#              batch_size=batch_size,\n",
    "#              epochs=epochs,\n",
    "#              validation_data=(x_test, y_test),\n",
    "#              shuffle=True)\n",
    "#    print('fit is done')\n",
    "#else:\n",
    "#    sys.exit(\"this has been snipped from the code\")\n",
    "#    \n",
    "#\n",
    "## Save model and weights\n",
    "#if not os.path.isdir(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "#model_path = os.path.join(save_dir, model_name)\n",
    "#model.save(model_path)\n",
    "#print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "#scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "#print('Test loss:', scores[0])\n",
    "#print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "here\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_numeric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a98ad2f69182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Convert labels to categorical one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mone_hot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_numeric' is not defined"
     ]
    }
   ],
   "source": [
    "#### the following is copied directly from \n",
    "# keras examples\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "x_train = foo['images']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "\n",
    "model.add(Dense(32, input_shape=(480, 640, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# compile for a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# print a few randomly chosen\n",
    "import random\n",
    "randlist = []\n",
    "for i in range(10):\n",
    "    randlist.append(random.randrange(len(foo['target'])))\n",
    "\n",
    "for j in randlist:\n",
    "    print(str(foo['target'][j]))\n",
    "\n",
    "\n",
    "print(\"here\")\n",
    "\n",
    "\n",
    "import keras.utils\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(target_numeric, num_classes=3)\n",
    "\n",
    "for j in randlist:\n",
    "    print(one_hot_labels[j])\n",
    "\n",
    "    \n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(foo['images'], one_hot_labels, epochs=10, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "[5]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[5]\n",
      "[9]\n",
      "[4]\n",
      "[4]\n",
      "[1]\n",
      "[9]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "print(type(labels))\n",
    "print(labels.shape)\n",
    "print(type(labels[0]))\n",
    "print(labels[0].shape)\n",
    "for i in range(10):\n",
    "    print(labels[i])\n",
    "\n",
    "import keras.utils\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "for i in range(10):\n",
    "    print(one_hot_labels[i])\n",
    "\n",
    "print(type(data))\n",
    "print(data[0].shape)\n",
    "    \n",
    "## Train the model, iterating on the data in batches of 32 samples\n",
    "#model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
