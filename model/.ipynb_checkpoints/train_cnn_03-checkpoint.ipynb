{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on:githug.com/\n",
    "# githug.com/experiencor.self-driving-toy-car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import os, random\n",
    "import keras.utils.vis_utils as vutil\n",
    "from IPython.display import SVG\n",
    "import tensorflow as tf\n",
    "import keras.models as models\n",
    "from keras.optimizers import SGD\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalAveragePooling2D, Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.animation as animation\n",
    "import sys\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "FRAME_H =  80\n",
    "FRAME_W = 160\n",
    "\n",
    "STEER_MIDPT = 1500.\n",
    "STEER_UPPER = 2000.\n",
    "STEER_LOWER = 1000.\n",
    "\n",
    "def draw_steer(image, steer, color, text=''):\n",
    "    center = (image.shape[1]/2, image.shape[0]/2)\n",
    "    offset = (image.shape[1]/2 + int(steer*image.shape[1]/2), image.shape[0]/2)\n",
    "    \n",
    "    cv2.arrowedLine(image, center, offset, color=color, thickness=1, tipLength=0.4)      \n",
    "    \n",
    "    return image\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometime = lambda aug: iaa.Sometimes(0.3, aug)\n",
    "sequence = iaa.Sequential([ sometime(iaa.GaussianBlur((0, 1.5))), # blur images with a sigma between 0 and 3.0\n",
    "                            sometime(iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))), # sharpen images\n",
    "                            sometime(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 3.), per_channel=0.5)), # add gaussian noise to images\n",
    "                            sometime(iaa.Dropout((0.0, 0.1))), # randomly remove up to 10% of the pixels\n",
    "                            sometime(iaa.CoarseDropout((0.10, 0.30), size_percent=(0.02, 0.05), per_channel=0.2)),\n",
    "                            sometime(iaa.Add((-10, 10), per_channel=0.5)), # change brightness of images (by -10 to 10 of original value)\n",
    "                          ],\n",
    "                          random_order=True # do all of the above in random order\n",
    "                         )\n",
    "\n",
    "def equalize(image):\n",
    "    norm=np.zeros((image.shape), np.float32)\n",
    "\n",
    "    norm[:,:,0]=cv2.equalizeHist(image[:,:,0])\n",
    "    norm[:,:,1]=cv2.equalizeHist(image[:,:,1])\n",
    "    norm[:,:,2]=cv2.equalizeHist(image[:,:,2])\n",
    "\n",
    "    return norm\n",
    "\n",
    "def normalize(image):\n",
    "    image = image - np.mean(image, axis=(0,1))\n",
    "    image = image / np.std( image, axis=(0,1))\n",
    "    \n",
    "    return image\n",
    "\n",
    "def augment(image, steer):\n",
    "    image = sequence.augment_image(image)\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        shift = np.random.randint(-2,2)\n",
    "        \n",
    "        if shift > 0:\n",
    "            image[-shift:,:,:] = 0\n",
    "            image[:-shift,:,:] = image[shift:,:,:]\n",
    "        elif shift < 0:\n",
    "            image[:-shift,:,:] = 0\n",
    "            image[-shift:,:,:] = image[:shift,:,:]\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steer = -steer\n",
    "                \n",
    "    return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, sessions, batch_size, shuffle = True, terminate = False, jitter = True, norm=True):\n",
    "        self.images = []\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.terminate = terminate\n",
    "        self.jitter = jitter\n",
    "        self.norm = norm\n",
    "\n",
    "        for session in sessions:\n",
    "            image_path = session + '/image/'\n",
    "            label_path = session + '/steer/'\n",
    "\n",
    "            self.images += sorted([image_path + path for path in os.listdir(image_path)])\n",
    "\n",
    "        if shuffle: np.random.shuffle(self.images)\n",
    "\n",
    "    def get_gen(self):\n",
    "        num_img = len(self.images)\n",
    "        \n",
    "        l_bound = 0\n",
    "        r_bound = self.batch_size if self.batch_size < num_img else num_img    \n",
    "\n",
    "        while True:\n",
    "            if l_bound == r_bound:\n",
    "                if self.terminate:\n",
    "                    break\n",
    "                else:\n",
    "                    l_bound = 0\n",
    "                    r_bound = self.batch_size if self.batch_size < num_img else num_img\n",
    "                    if self.shuffle: np.random.shuffle(self.images)\n",
    "\n",
    "            x_batch = np.zeros((r_bound - l_bound, FRAME_H, FRAME_W, 3))\n",
    "            y_batch = np.zeros((r_bound - l_bound, 1))\n",
    "            currt_inst = 0        \n",
    "\n",
    "            for image_file in self.images[l_bound:r_bound]:\n",
    "                # construct each input\n",
    "                image = cv2.imread(image_file)\n",
    "\n",
    "                # construct each output\n",
    "                steer = open(image_file.replace('image', 'steer').replace('png', 'txt')).read()\n",
    "                steer = np.clip(float(steer), STEER_LOWER, STEER_UPPER)\n",
    "                steer = (float(steer) - STEER_MIDPT) / (STEER_UPPER - STEER_MIDPT)\n",
    "\n",
    "                if self.jitter: image, steer = augment(image, steer)\n",
    "                if self.norm:   image = normalize(image)\n",
    "\n",
    "                x_batch[currt_inst] = image\n",
    "                y_batch[currt_inst] = steer\n",
    "\n",
    "                currt_inst += 1\n",
    "                \n",
    "            yield x_batch, y_batch\n",
    "\n",
    "            l_bound = r_bound\n",
    "            r_bound = r_bound + self.batch_size\n",
    "            if r_bound > num_img: r_bound = num_img\n",
    "                \n",
    "    def get_size(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the network\n",
    "image_inp = Input(shape=(FRAME_H, FRAME_W, 3))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=(3, 5), activation='relu', padding='valid')(image_inp)\n",
    "x = Conv2D(filters=16, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = MaxPooling2D((4, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = Conv2D(filters=32, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = MaxPooling2D((4, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=4,  kernel_size=(1, 1), activation='linear', padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1, activation='tanh', kernel_regularizer='l1')(x)\n",
    "\n",
    "angle_out = x\n",
    "\n",
    "model = Model(inputs=[image_inp], outputs=[angle_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 80, 160, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 78, 156, 16)       736       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 76, 152, 16)       3856      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 19, 76, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 17, 72, 32)        7712      \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 15, 68, 32)        15392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 34, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 3, 34, 4)          132       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 408)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 409       \n",
      "=================================================================\n",
      "Total params: 28,237\n",
      "Trainable params: 28,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train non-recurrent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stop  = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=2, mode='min', verbose=1)\n",
    "checkpoint  = ModelCheckpoint('weights.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "batch_num = 32\n",
    "session_t = ['../network/drive_trial_0', '../network/drive_trial_2']\n",
    "session_v = ['../network/drive_trial_1', '../network/drive_trial_3']\n",
    "\n",
    "gen_train = BatchGenerator(session_t, batch_num)\n",
    "gen_valid = BatchGenerator(session_v, batch_num, jitter = False)\n",
    "\n",
    "num_train = gen_train.get_size()/batch_num\n",
    "num_valid = gen_valid.get_size()/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    #y_true = tf.Print(y_true, [tf.reduce_mean(y_true - y_pred)], message='DEBUG', summarize=10000) \n",
    "    \n",
    "    # custom loss 1\n",
    "    #y_pred = tf.clip_by_value(y_pred, -1+1e-7, 1-1e-7)\n",
    "    #loss = -((1. - y_true) * tf.log(1. - y_pred) + (1. + y_true) * tf.log(1. + y_pred))\n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    # custom loss 2\n",
    "    loss = tf.square(y_true - y_pred)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    # custom loss 3\n",
    "    #loss = tf.abs(y_true - y_pred)\n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../network/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chris/Documents/projects_scikit_tensorflow/metrowest_scikit_tensorflow_cnn_test/metrowest_scikit_tensorflow_cnn_car/src\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-632ec150c761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtb_counter\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../logs/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../logs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir('../logs/'))\n",
    "\n",
    "\n",
    "tb_counter  = max([int(num) for num in os.listdir('../logs/')]) + 1\n",
    "tensorboard = TensorBoard(log_dir='../logs/' + str(tb_counter), histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "minimizer = SGD(lr=0.0001)\n",
    "\n",
    "#model.compile(loss=custom_loss, optimizer=minimizer)\n",
    "model.compile(loss=custom_loss, optimizer='adam')\n",
    "\n",
    "model.fit_generator(generator = gen_train.get_gen(),\n",
    "                    steps_per_epoch = num_train, \n",
    "                    epochs  = 3, \n",
    "                    verbose = 1,\n",
    "                    validation_data = gen_valid.get_gen(), \n",
    "                    validation_steps = num_valid, \n",
    "                    callbacks = [early_stop, checkpoint, tensorboard], \n",
    "                    max_q_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
