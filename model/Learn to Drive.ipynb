{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrowest machine learning self-driving car\n",
    "#### The project is a self-driving car.  Refer to the .pdf document for details\n",
    "#### This notebook trains the the CNN.\n",
    "#### References:\n",
    "#### https://www.meetup.com/Natick-Artificial-Intelligence-Meetup/\n",
    "#### https://github.com/experiencor.self-driving-toy-car/\n",
    "#### http://vision.stanford.edu/teaching/cs231n/\n",
    "#### https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import os, random\n",
    "import keras.utils.vis_utils as vutil\n",
    "from IPython.display import SVG\n",
    "import tensorflow as tf\n",
    "import keras.models as models\n",
    "from keras.optimizers import SGD\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalAveragePooling2D, Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.animation as animation\n",
    "import sys\n",
    "\n",
    "import sys\n",
    "sys.path.append('../lib')\n",
    "from metrowestcar_image_params import IParams\n",
    "\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "FRAME_H = IParams.height\n",
    "FRAME_W = IParams.width\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation (future)\n",
    "def augment(image, steer):\n",
    "    return image, steer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from ../data/pictures_test\n",
      "loading from ../data/pictures_test\n",
      "(11, 480, 640, 3)\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data.\n",
    "import sys\n",
    "sys.path.append('../lib')\n",
    "\n",
    "from metrowestcar_file_io import FileReader\n",
    "file_reader = FileReader()\n",
    "\n",
    "dir_list = [\n",
    "    \"../data/pictures_test\",\n",
    "]\n",
    "\n",
    "image_array = file_reader.read_images_from_list_of_directories(dir_list)\n",
    "steering_array = file_reader.read_steering_from_list_of_directories(dir_list)\n",
    "\n",
    "print(image_array.shape)   \n",
    "print(steering_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8855a233a1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteering_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#aa = np.vstack((a,a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(aa)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects_scikit_tensorflow/env/local/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "full_data = np.vstack((steering_array, image_array))\n",
    "print(full_data.shape)\n",
    "\n",
    "#aa = np.vstack((a,a))\n",
    "#print(aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "# if shuffle: np.random.shuffle(self.images)\n",
    "import numpy as np\n",
    "        \n",
    "arr = np.array([\n",
    "    [0, 1],\n",
    "    [2 ,3],\n",
    "    [4, 5],\n",
    "    [6, 7],\n",
    "    [8, 9],\n",
    "])\n",
    "print(arr.shape)\n",
    "print(arr)\n",
    "print(  arr[:][0], arr[:][1]  )\n",
    "\n",
    "#foo = np.array([[11],[12],[13],[14],[15]])\n",
    "#print(foo)\n",
    "#\n",
    "#bar = np.stack(foo, foo)\n",
    "#\n",
    "#print(bar)\n",
    "\n",
    "#arr = arr[np.newaxis]\n",
    "#print(arr)\n",
    "\n",
    "#            image = image[np.newaxis]\n",
    "#            my_images = np.append(my_images, image, axis=0)\n",
    "        \n",
    "        \n",
    "#np.random.shuffle(arr)\n",
    "#print(arr)\n",
    "\n",
    "#foo = np.random.shuffle(np.array(range(5)))\n",
    "#print(foo)\n",
    "\n",
    "#arr = np.array([image_array, steering_array])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]]\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array((1,2,3))\n",
    "aa = np.vstack((a,a))\n",
    "print(aa)\n",
    "\n",
    "b = np.array((2,3,4))\n",
    "print(np.vstack((aa,b)))\n",
    "\n",
    "#print\n",
    "#a = np.array([[1],[2],[3]])\n",
    "#b = np.array([[2],[3],[4]])\n",
    "#print(np.hstack((a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-651a861a9b0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects_scikit_tensorflow/env/local/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])\n",
    "print(np.stack(a, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "from metrowestcar_display import Displayer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, val, and test sets. In addition we will\n",
    "# create a small development set as a subset of the training data;\n",
    "# we can use this for development so our code runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Model (CNN Classifier)\n",
    "\n",
    "Code for this section is in **lib/model_cnn.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the network\n",
    "image_inp = Input(shape=(FRAME_H, FRAME_W, 3))\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=(3, 5), activation='relu', padding='valid')(image_inp)\n",
    "x = Conv2D(filters=16, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = MaxPooling2D((4, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = Conv2D(filters=32, kernel_size=(3, 5), activation='relu', padding='valid')(x)\n",
    "x = MaxPooling2D((4, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=4,  kernel_size=(1, 1), activation='linear', padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1, activation='tanh', kernel_regularizer='l1')(x)\n",
    "\n",
    "angle_out = x\n",
    "\n",
    "model = Model(inputs=[image_inp], outputs=[angle_out])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 478, 636, 16)      736       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 476, 632, 16)      3856      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 119, 316, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 117, 312, 32)      7712      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 115, 308, 32)      15392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 154, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 154, 4)        132       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 17248)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17249     \n",
      "=================================================================\n",
      "Total params: 45,077\n",
      "Trainable params: 45,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights to file\n",
    "model.save_weights('../network/weights.hdf5')\n",
    "model.load_weights('../network/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss as a function of iteration number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on training and validation set\n",
    "y_train_pred = svm.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = svm.predict(X_val)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop  = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=2, mode='min', verbose=1)\n",
    "checkpoint  = ModelCheckpoint('weights.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "batch_num = 32\n",
    "session_t = ['../network/drive_trial_0', '../network/drive_trial_2']\n",
    "session_v = ['../network/drive_trial_1', '../network/drive_trial_3']\n",
    "\n",
    "gen_train = BatchGenerator(session_t, batch_num)\n",
    "gen_valid = BatchGenerator(session_v, batch_num, jitter = False)\n",
    "\n",
    "num_train = gen_train.get_size()/batch_num\n",
    "num_valid = gen_valid.get_size()/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    #y_true = tf.Print(y_true, [tf.reduce_mean(y_true - y_pred)], message='DEBUG', summarize=10000) \n",
    "    \n",
    "    # custom loss 1\n",
    "    #y_pred = tf.clip_by_value(y_pred, -1+1e-7, 1-1e-7)\n",
    "    #loss = -((1. - y_true) * tf.log(1. - y_pred) + (1. + y_true) * tf.log(1. + y_pred))\n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    # custom loss 2\n",
    "    loss = tf.square(y_true - y_pred)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    # custom loss 3\n",
    "    #loss = tf.abs(y_true - y_pred)\n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir('../logs/'))\n",
    "\n",
    "\n",
    "tb_counter  = max([int(num) for num in os.listdir('../logs/')]) + 1\n",
    "tensorboard = TensorBoard(log_dir='../logs/' + str(tb_counter), histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "minimizer = SGD(lr=0.0001)\n",
    "\n",
    "#model.compile(loss=custom_loss, optimizer=minimizer)\n",
    "model.compile(loss=custom_loss, optimizer='adam')\n",
    "\n",
    "model.fit_generator(generator = gen_train.get_gen(),\n",
    "                    steps_per_epoch = num_train, \n",
    "                    epochs  = 3, \n",
    "                    verbose = 1,\n",
    "                    validation_data = gen_valid.get_gen(), \n",
    "                    validation_steps = num_valid, \n",
    "                    callbacks = [early_stop, checkpoint, tensorboard], \n",
    "                    max_q_size = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
